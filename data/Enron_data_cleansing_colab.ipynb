{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69abf795",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/akikoiwamizu/enron-vizards/blob/main/data/Enron_data_cleansing_collab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cH-m0HEN2z7B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH-m0HEN2z7B",
    "outputId": "d9bdbbeb-d918-4248-fd15-b39736705c52"
   },
   "outputs": [],
   "source": [
    "# Downloading the file from Kaggle requires you to go to the account tab of the My Profile \n",
    "# section and click on Create New API Token. This will download a kaggle.json file.\n",
    "\n",
    "## ! mkdir /root/.kaggle/\n",
    "## ! cp kaggle.json /root/.kaggle/\n",
    "## ! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Once you have the kaggle.json file download, move it to this location on your local machine\n",
    "# to access the Kaggle API. For me, the following command did the trick:\n",
    "\n",
    "##! cp ~/Downloads/kaggle.json  ~/.kaggle/\n",
    "##! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will fail if the files are already on your local machine in this directory.\n",
    "\n",
    "##! kaggle datasets download wcukierski/enron-email-dataset\n",
    "##! unzip enron-email-dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "il_byWMa3GaR",
   "metadata": {
    "id": "il_byWMa3GaR"
   },
   "outputs": [],
   "source": [
    "# Remove zip file after csv successfully obtained.\n",
    "\n",
    "##! rm enron-email-dataset.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650e5ff",
   "metadata": {
    "id": "b650e5ff"
   },
   "source": [
    "# Enron data cleansing\n",
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbec61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2dbec61",
    "outputId": "ca5fbbf1-c8b0-4140-9d51-3b43ce87b13e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from email.parser import Parser\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31fa30",
   "metadata": {
    "id": "8b31fa30",
    "outputId": "4a031711-b1ef-450d-ab2a-6a6482b55283"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8fe28",
   "metadata": {
    "id": "54b8fe28",
    "outputId": "0599f3ab-3d62-47df-9de2-551d96ffecb5"
   },
   "outputs": [],
   "source": [
    "emails_lst = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    email = Parser().parsestr(df.message[i])\n",
    "    emails_lst.append(dict(zip(email.keys(), email.values())))\n",
    "    emails_lst[-1][\"Body\"] = email.get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5df2d0",
   "metadata": {
    "id": "5f5df2d0",
    "outputId": "b438b40f-b717-4407-8666-92ec8d580ad6"
   },
   "outputs": [],
   "source": [
    "emails = pd.DataFrame(emails_lst)\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d906e",
   "metadata": {
    "id": "d89d906e"
   },
   "source": [
    "We just want to keep the useful stuff and drop all unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b34ce",
   "metadata": {
    "id": "ca0b34ce",
    "outputId": "7ec609a2-efee-491f-a803-732f10372c2e"
   },
   "outputs": [],
   "source": [
    "emails.drop(['Message-ID','Mime-Version','Content-Type','Content-Transfer-Encoding','X-FileName'], axis=1, inplace=True)\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190ef86",
   "metadata": {
    "id": "b190ef86"
   },
   "source": [
    "Now let's have a look on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03211ae4",
   "metadata": {
    "id": "03211ae4",
    "outputId": "7e20cc16-625e-4bbd-89d1-6160af6c3ce9"
   },
   "outputs": [],
   "source": [
    "display(emails.describe())\n",
    "emails.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e6948",
   "metadata": {
    "id": "766e6948"
   },
   "source": [
    "There seem to be a couple of NaNs for the authors and recicpients of some emails which makes them useless for our analysis. We hence drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e5888",
   "metadata": {
    "id": "1f3e5888",
    "outputId": "241cf383-2d16-4fe9-ccc7-de928a16daca"
   },
   "outputs": [],
   "source": [
    "emails.dropna(subset=[\"X-From\",\"X-To\"], how=\"all\", inplace=True)\n",
    "emails.reset_index(drop=True,inplace=True)\n",
    "emails.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9d423",
   "metadata": {
    "id": "adb9d423"
   },
   "source": [
    "Let's try to get the date into a nice format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2281a2",
   "metadata": {
    "id": "fb2281a2",
    "outputId": "d6034636-e1e5-4685-9a67-40e33fec1268"
   },
   "outputs": [],
   "source": [
    "emails = pd.concat((emails, pd.DataFrame(np.reshape([y for x in emails.Date.apply(lambda x: x.split()[1:6]) for y in x],\n",
    "                                                (len(emails),5)), \n",
    "             columns=[\"day\",\"month\",\"year\",\"time\",\"tzdiff\"])), axis=1)\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61256e5",
   "metadata": {
    "id": "c61256e5"
   },
   "outputs": [],
   "source": [
    "#Convert to int\n",
    "emails.day = emails.day.astype(int)\n",
    "emails.year = emails.year.astype(int)\n",
    "#Convert month name to number\n",
    "d = dict(zip(pd.date_range('2000-01-01', freq='M', periods=12).strftime('%b'),range(1,13)))\n",
    "emails.month = emails.month.map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e76ad",
   "metadata": {
    "id": "cd1e76ad"
   },
   "source": [
    "The Enron scandal ended with its bankrupcy in Dec 2001. Hence, data before this date should be irrelevant or non-existent. But we could also go for 2007 when the company completely ceased to exist. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04942456",
   "metadata": {
    "id": "04942456",
    "outputId": "276b838f-02cd-4b8b-bbc3-9b920750ca99",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(emails[emails.year > 2001])\n",
    "display(emails[emails.year > 2007])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d246bd",
   "metadata": {
    "id": "86d246bd"
   },
   "source": [
    "There is some erroneous data with years in the future. Let's stick to the 2007 threshold then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98de29d",
   "metadata": {
    "id": "e98de29d",
    "outputId": "5dc96f24-1cd2-4260-ea45-2c117b48941f"
   },
   "outputs": [],
   "source": [
    "emails = emails[emails.year <= 2007]\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6da74d",
   "metadata": {
    "id": "8b6da74d"
   },
   "source": [
    "What about minimum values? Enron was founded in 1985 so that seems to be a reasonable threshold. However, Enron was founded by a merger of two companies and one of them was founded in 1931. But emails were invented and used in companies from 1975 on. Let's use this a threshold instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7efc2",
   "metadata": {
    "id": "02e7efc2",
    "outputId": "2c649d3d-4a7f-4c1b-c5a8-2ddcf9c361d6"
   },
   "outputs": [],
   "source": [
    "emails[emails.year < 1975]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fce2dd",
   "metadata": {
    "id": "13fce2dd"
   },
   "source": [
    "Seems like we will drop junk data. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919543f",
   "metadata": {
    "id": "a919543f",
    "outputId": "89edafa5-b28c-4194-c2c2-dfa1a7245e6a"
   },
   "outputs": [],
   "source": [
    "emails = emails[emails.year >= 1975]\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1521c8d",
   "metadata": {
    "id": "b1521c8d"
   },
   "source": [
    "Ok, now let's take a look on the names of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bbf646",
   "metadata": {
    "id": "29bbf646",
    "outputId": "1eb3c6f6-4d91-48f1-fbbe-a13772922cf9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people = set().union(*[emails[\"X-To\"],emails[\"X-From\"]])\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0d936",
   "metadata": {
    "id": "c1c0d936"
   },
   "source": [
    "There are some issues with the names. Let's fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a4817",
   "metadata": {
    "id": "133a4817",
    "outputId": "3eb57ef3-4caf-4557-9806-f246dc72d643",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's get rid of everything after \"<\"\n",
    "emails[\"X-To\"] = emails[\"X-To\"].apply(lambda x: x[:x.find(\"<\")-1] if x.find(\"<\") > 0 else x)\n",
    "emails[\"X-From\"] = emails[\"X-From\"].apply(lambda x: x[:x.find(\"<\")-1] if x.find(\"<\") > 0 else x)\n",
    "emails[\"X-cc\"] = emails[\"X-cc\"].apply(lambda x: x[:x.find(\"<\")-1] if x.find(\"<\") > 0 else x)\n",
    "emails[\"X-bcc\"] = emails[\"X-bcc\"].apply(lambda x: x[:x.find(\"<\")-1] if x.find(\"<\") > 0 else x)\n",
    "emails[[\"X-To\",\"X-From\",\"X-cc\",\"X-bcc\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoying_lst = emails[\"X-To\"][emails[\"X-To\"].str.len().sort_values(ascending=False)[:10].index]\n",
    "less_annoying_lst = emails[\"X-To\"].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef418af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name_format(names):\n",
    "    #Variables\n",
    "    emails_dict = {}\n",
    "    emails_list = []\n",
    "    name_drop = []\n",
    "    remaining = []\n",
    "    single = []\n",
    "    multiple = []\n",
    "    clean_names = []\n",
    "    #One person with format \"lastName, firstName optMiddleName\"\n",
    "    if names.strip(\",\").count(\",\") == 1:\n",
    "        if len(names.split()) > 3:\n",
    "            multiple = names.strip(\"\\'\").split(\", \")\n",
    "        else:\n",
    "            single = names.strip(\"\\'\").split(\", \")\n",
    "            if len(single) == 1:\n",
    "                single = single[0].strip(\"\\'\").split(\",\")\n",
    "            single = single[1] + \" \" + single[0]\n",
    "    else:\n",
    "        #Separate string into list of strings\n",
    "        names = names.strip(\",\").split(\", \")\n",
    "        #Separate email addresses from name and save in dictionary\n",
    "        names = [x.replace('\\\\',\"\").replace('\\\"',\"\").strip(' ') for x in names]\n",
    "        for name in names:\n",
    "            #Assuming only one email per name\n",
    "            email = re.findall(r'<[\\w.+-]+@[\\w-]+\\.[\\w.-]+>', name)\n",
    "            if len(email) > 0:\n",
    "                if len(name) > len(email[0]):\n",
    "                    emails_dict[email[0]] = name.replace(email[0],\"\").replace(\".\",\" \").strip(\" \").title()\n",
    "                else:\n",
    "                    emails_list.append(email[0].replace(\".\",\" \").title())\n",
    "                name_drop.append(name)\n",
    "        #Lookup names in email_dict\n",
    "        for i, email in enumerate(emails_list):\n",
    "            if email in emails_dict.values():\n",
    "                emails_list[i] = emails_dict.get(i)    \n",
    "        remaining = list(set(names) - set(name_drop))\n",
    "        clean_names = list(set(emails_list + list(emails_dict.values()) + remaining))\n",
    "    if single:\n",
    "        clean_names.append(single)\n",
    "    if multiple:\n",
    "        clean_names = clean_names + multiple\n",
    "    return clean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030935c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's extract lists of recipients\n",
    "emails[\"X-To\"] = emails[\"X-To\"].apply(lambda x: clean_name_format(x))\n",
    "emails[\"X-From\"] = emails[\"X-From\"].apply(lambda x: clean_name_format(x))\n",
    "emails[\"X-cc\"] = emails[\"X-cc\"].apply(lambda x: clean_name_format(x))\n",
    "emails[\"X-bcc\"] = emails[\"X-bcc\"].apply(lambda x: clean_name_format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf64854",
   "metadata": {},
   "source": [
    "Let's see if this looks better now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098d5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#people = set().union(*[emails[\"X-To\"].apply(pd.Series).stack().reset_index(drop=True),\n",
    "#              emails[\"X-From\"].apply(pd.Series).stack().reset_index(drop=True),\n",
    "#              emails[\"X-cc\"].apply(pd.Series).stack().reset_index(drop=True),\n",
    "#              emails[\"X-bcc\"].apply(pd.Series).stack().reset_index(drop=True)])\n",
    "#print(len(people))\n",
    "#people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958d5fb",
   "metadata": {
    "id": "8958d5fb"
   },
   "source": [
    "Looks a lot better now. The EDA will show if we have other issues with the data, but for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email recipients limited to highest 10k\n",
    "authors = pd.Series([item for row in emails[\"X-From\"] for item in row if item])\n",
    "authors = pd.DataFrame({\"Name\" : authors.value_counts().index,\n",
    "                            \"Sent\" : authors.value_counts()}).reset_index(drop=True).sort_values(by=\"Sent\", ascending=False)\n",
    "\n",
    "# Email recipients limited to highest 10k\n",
    "all_recipients = emails[\"X-To\"] + emails[\"X-cc\"] + emails[\"X-bcc\"]\n",
    "recipients = pd.Series([item for row in all_recipients for item in row if item])\n",
    "recipients = pd.DataFrame({\"Name\" : recipients.value_counts().index,\n",
    "                            \"Received\" : recipients.value_counts()}).reset_index(drop=True).sort_values(by=\"Received\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define culprits and clean dataset for different spellings\n",
    "key_people = ['Kenneth Lay', 'Jeffrey Skilling', 'Andrew Fastow']\n",
    "\n",
    "kenneth_lay = authors.Name[authors.Name.apply(lambda x: \"Ken Lay\" in x)]\n",
    "jeff_skilling = authors.Name[authors.Name.apply(lambda x: \"Jeff Skilling\" in x)]\n",
    "andrew_fastow = [\"Andrew S Fastow\"]\n",
    "\n",
    "# Clean dataset with correct names\n",
    "def clean_names(name_list):\n",
    "    for i, name in enumerate(name_list):\n",
    "        if name in kenneth_lay:\n",
    "            name_list[i] = 'Kenneth Lay'\n",
    "        elif name in jeff_skilling:\n",
    "            name_list[i] = 'Jeffrey Skilling'\n",
    "        elif name in andrew_fastow:\n",
    "            name_list[i] = 'Andrew Fastow'\n",
    "        return name_list\n",
    "    \n",
    "emails[\"X-From\"] = emails[\"X-From\"].apply(lambda x: clean_names(x))\n",
    "emails[\"X-To\"] = emails[\"X-To\"].apply(lambda x: clean_names(x)) \n",
    "emails[\"X-cc\"] = emails[\"X-cc\"].apply(lambda x: clean_names(x)) \n",
    "emails[\"X-bcc\"] = emails[\"X-bcc\"].apply(lambda x: clean_names(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995b310",
   "metadata": {
    "id": "2995b310"
   },
   "outputs": [],
   "source": [
    "emails.to_json(\"emails_clean.json\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Enron_data_cleansing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
